{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTMJB0OmEqfAaVXFC3lSBE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ckraymond/ABEL/blob/master/Raymond_Final_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ao75mneudt50",
        "outputId": "5e97a064-c378-4fbf-b25a-84991a59617d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 2s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "-----------------------\n",
            "Stats for Part A\n",
            "Mean: 809.00\n",
            "Standard Deviation: 1139.14\n",
            "-----------------------\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "-----------------------\n",
            "Stats for Part B\n",
            "Mean: 674.20\n",
            "Standard Deviation: 115.75\n",
            "-----------------------\n",
            "The difference between the MEAN of MSE between Part B and Part A is -134.80\n",
            "The difference between the STANDARD DEVIATION of MSE between Part B and Part A is -1023.39\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "-----------------------\n",
            "Stats for Part C\n",
            "Mean: 221.70\n",
            "Standard Deviation: 30.63\n",
            "-----------------------\n",
            "The difference between the MEAN of MSE between Part C and Part B is -452.50\n",
            "The difference between the STANDARD DEVIATION of MSE between Part C and Part B is -85.12\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 5ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 4ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "-----------------------\n",
            "Stats for Part D\n",
            "Mean: 121.87\n",
            "Standard Deviation: 18.89\n",
            "-----------------------\n",
            "The difference between the MEAN of MSE between Part D and Part B is -552.33\n",
            "The difference between the STANDARD DEVIATION of MSE between Part D and Part B is -96.86\n"
          ]
        }
      ],
      "source": [
        "from pickle import FALSE\n",
        "# Deep Learning & Nueral Networks Lab\n",
        "## Colin Raymond\n",
        "\n",
        "# Notes to grader\n",
        "''' Hey! Thanks for grading my assignment. I have all four sections as one file\n",
        "per the assignment instructions. Rather than have you run the program which takes\n",
        "forever I've copied and pasted the output below.\n",
        "\n",
        "In general, we see a decrease in both the Mean and Standard Deviation of each\n",
        "step as we move from Part A to Part B. There is an enormous decrease in the\n",
        "standard deviation, but the decrease levels off in Parts C and D. '''\n",
        "\n",
        "# Copied and Pasted Output\n",
        "'''\n",
        "-----------------------\n",
        "Stats for Part A\n",
        "Mean: 809.00\n",
        "Standard Deviation: 1139.14\n",
        "-----------------------\n",
        "-----------------------\n",
        "Stats for Part B\n",
        "Mean: 674.20\n",
        "Standard Deviation: 115.75\n",
        "-----------------------\n",
        "The difference between the MEAN of MSE between Part B and Part A is -134.80\n",
        "The difference between the STANDARD DEVIATION of MSE between Part B and Part A is -1023.39\n",
        "-----------------------\n",
        "Stats for Part C\n",
        "Mean: 221.70\n",
        "Standard Deviation: 30.63\n",
        "-----------------------\n",
        "The difference between the MEAN of MSE between Part C and Part B is -452.50\n",
        "The difference between the STANDARD DEVIATION of MSE between Part C and Part B is -85.12\n",
        "-----------------------\n",
        "Stats for Part D\n",
        "Mean: 121.87\n",
        "Standard Deviation: 18.89\n",
        "-----------------------\n",
        "The difference between the MEAN of MSE between Part D and Part B is -552.33\n",
        "The difference between the STANDARD DEVIATION of MSE between Part D and Part B is -96.86\n",
        "'''\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "## Import the data\n",
        "concrete_data = pd.read_csv('https://cocl.us/concrete_data')\n",
        "concrete_data_columns = concrete_data.columns\n",
        "\n",
        "## Split out the independent and dependant variables\n",
        "base_predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']]\n",
        "base_targets = concrete_data['Strength']\n",
        "\n",
        "## Function that creates the Keras model which accepts as an input the number of hidden layers\n",
        "def regression_model(num_layers):\n",
        "  layer_count = num_layers-1  # Counter for the while loop\n",
        "\n",
        "  ### create model\n",
        "  model = Sequential()\n",
        "  model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
        "\n",
        "  ### Using layer_count as index go add in hidden layers\n",
        "  while layer_count > 0:\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    layer_count -= 1\n",
        "\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  ### compile model\n",
        "  model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "  return model\n",
        "\n",
        "## Creating a function that goes through the entire process and takes inputs to actually determine what to do\n",
        "def model_run(num_epochs, num_layers, predictors, targets, i):\n",
        "\n",
        "  ## Split the data into training and testing by holding 30% for testing\n",
        "  predictors_train, predictors_test, targets_train, targets_test = train_test_split(predictors, targets, test_size=0.3, random_state=4)\n",
        "  n_cols = predictors.shape[1] # number of predictors for the model\n",
        "\n",
        "  ## Train and fit the Keras model\n",
        "  model = regression_model(num_layers)\n",
        "  model.fit(predictors_train, targets_train, validation_split=0.3, epochs=num_epochs, verbose=0)\n",
        "\n",
        "  ## Evaluate the model on the test data and compute the MSE\n",
        "  predictions = model.predict(predictors_test)\n",
        "  mse = mean_squared_error(targets_test, predictions[:,0])\n",
        "\n",
        "  return mse\n",
        "\n",
        "## Create a function to calculate and print the mean and standard deviation\n",
        "def print_stats(mse_array, label):\n",
        "  mean = np.mean(mse_array)\n",
        "  std = np.std(mse_array)\n",
        "\n",
        "  print(\"-----------------------\")\n",
        "  print(\"Stats for %s\" % label)\n",
        "  print(\"Mean: %.2f\" % mean)\n",
        "  print(\"Standard Deviation: %.2f\" % std)\n",
        "  print(\"-----------------------\")\n",
        "\n",
        "# Part A. Build a baseline model (5 marks)\n",
        "# Use the Keras library to build a neural network with the following:\n",
        "# - One hidden layer of 10 nodes, and a ReLU activation function\n",
        "# - Use the adam optimizer and the mean squared error  as the loss function.\n",
        "\n",
        "# 1. Randomly split the data into a training and test sets by holding 30% of the data for testing. You can use the train_test_split helper function from Scikit-learn.\n",
        "# 2. Train the model on the training data using 50 epochs.\n",
        "# 3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n",
        "# 4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\n",
        "# 5. Report the mean and the standard deviation of the mean squared errors.\n",
        "\n",
        "mse_array_a = []\n",
        "for i in range(50):\n",
        "  mse_array_a.append(model_run(50, 1, base_predictors, base_targets, i))\n",
        "print_stats(mse_array_a, \"Part A\")\n",
        "\n",
        "# B. Normalize the data (5 marks)\n",
        "# Repeat Part A but use a normalized version of the data. Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation.\n",
        "# How does the mean of the mean squared errors compare to that from Step A?\n",
        "\n",
        "# Normalize the data\n",
        "norm_predictors = (base_predictors - base_predictors.mean()) / base_predictors.std()\n",
        "\n",
        "mse_array_b = []\n",
        "for i in range(50):\n",
        "  mse_array_b.append(model_run(50, 1, norm_predictors, base_targets, i))\n",
        "\n",
        "print_stats(mse_array_b, \"Part B\")\n",
        "print(\"The difference between the MEAN of MSE between Part B and Part A is %.2f\" % (np.mean(mse_array_b) - np.mean(mse_array_a)))\n",
        "print(\"The difference between the STANDARD DEVIATION of MSE between Part B and Part A is %.2f\" % (np.std(mse_array_b) - np.std(mse_array_a)))\n",
        "\n",
        "\n",
        "# C. Increate the number of epochs (5 marks)\n",
        "# Repeat Part B but use 100 epochs this time for training.\n",
        "# How does the mean of the mean squared errors compare to that from Step B?\n",
        "\n",
        "mse_array_c = []\n",
        "for i in range(50):\n",
        "  mse_array_c.append(model_run(100, 1, norm_predictors, base_targets, i))\n",
        "\n",
        "print_stats(mse_array_c, \"Part C\")\n",
        "print(\"The difference between the MEAN of MSE between Part C and Part B is %.2f\" % (np.mean(mse_array_c) - np.mean(mse_array_b)))\n",
        "print(\"The difference between the STANDARD DEVIATION of MSE between Part C and Part B is %.2f\" % (np.std(mse_array_c) - np.std(mse_array_b)))\n",
        "\n",
        "# D. Increase the number of hidden layers (5 marks)\n",
        "# Repeat part B but use a neural network with the following instead:\n",
        "# - Three hidden layers, each of 10 nodes and ReLU activation function.\n",
        "# How does the mean of the mean squared errors compare to that from Step B?\n",
        "\n",
        "mse_array_d = []\n",
        "for i in range(50):\n",
        "  mse_array_d.append(model_run(100, 3, norm_predictors, base_targets, i))\n",
        "\n",
        "print_stats(mse_array_d, \"Part D\")\n",
        "print(\"The difference between the MEAN of MSE between Part D and Part B is %.2f\" % (np.mean(mse_array_d) - np.mean(mse_array_b)))\n",
        "print(\"The difference between the STANDARD DEVIATION of MSE between Part D and Part B is %.2f\" % (np.std(mse_array_d) - np.std(mse_array_b)))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HWB2BOLFxMhu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}